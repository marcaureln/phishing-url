{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract URL features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following features are extracted from the URL:\n",
    "\n",
    "- **URLLength**: Number of characters in the URL.\n",
    "- **Domain**: Domain name extracted from the URL.\n",
    "- **DomainLength**: Number of characters in the domain name.\n",
    "- **IsDomainIP**: Indicates if the domain name is an IP address.\n",
    "- **TLD**: TLD (Top Level Domain) is the last part of the domain name, such as .com or .edu.\n",
    "- **URLSimilarityIndex**:\n",
    "- **CharContinuationRate**: Ratio of the number of continuous characters in the URL.\n",
    "- **TLDLegitimateProb**:\n",
    "- **URLCharProb**:\n",
    "- **TLDLength**: Number of characters in the TLD.\n",
    "- **NoOfSubDomain**: Number of subdomains in the URL.\n",
    "- **HasObfuscation**: Indicates if the URL has obfuscated characters like %20, %4D, etc.\n",
    "- **NoOfObfuscatedChar**: Number of obfuscated characters in the URL.\n",
    "- **ObfuscationRatio**: Ratio of obfuscated characters in the URL.\n",
    "- **NoOfLettersInURL**: Number of letters in the URL.\n",
    "- **LetterRatioInURL**: Ratio of letters in the URL.\n",
    "- **NoOfDegitsInURL**: Number of digits in the URL.\n",
    "- **DegitRatioInURL**: Ratio of digits in the URL.\n",
    "- **NoOfEqualsInURL**: Number of equal signs (=) in the URL.\n",
    "- **NoOfQMarkInURL**: Number of question marks (?) in the URL.\n",
    "- **NoOfAmpersandInURL**: Number of ampersands (&) in the URL.\n",
    "- **NoOfOtherSpecialCharsInURL**: Number of special characters other than equals, question marks, and ampersands in the URL.\n",
    "- **SpacialCharRatioInURL**: Ratio of all special characters in the URL. A special character is any character that is not a letter or a digit.\n",
    "- **IsHTTPS**: Indicates if the webpage is running on unsecured HTTP (hypertext transfer protocol) or secured HTTPS.\n",
    "\n",
    "**Notes**:\n",
    "\n",
    "- We need to differentiate between URL and domain. For example, in the URL `https://www.google.com/search?q=python`, the domain is `www.google.com`. This is commonly referred to as the hostname. The domain is also commonly referred to as the base domain or the root domain (google.com). But, in our case, we'll refer to the hostname as the domain (which is ultimetly not incorrect).\n",
    "- Boolean features are converted to numerical values (0=False; 1=True)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import unquote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def IsDomainIP(domain):\n",
    "    # This regex will match any sequence of four numbers separated by dots. This is a simple way to check if a string is an IP address.\n",
    "    # However, it doesn't strictly validate IP addresses. For example, it will match 999.999.999.999, which is not a valid IP address.\n",
    "    ip_pattern = r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}'\n",
    "    is_ip = bool(re.search(ip_pattern, domain))\n",
    "    return int(is_ip)\n",
    "\n",
    "\n",
    "print(IsDomainIP('www.google.com'))  # 0\n",
    "print(IsDomainIP('192.168.1.1'))  # 1\n",
    "print(IsDomainIP('999.999.999.999'))  # 1 (True, but it's not a valid IP address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def NoOfSubDomain(domain):\n",
    "    # IP addresses are not domain names, thus they don't have subdomains. \n",
    "    # Subdomains are part of the DNS hierarchy and are only used in domain names.\n",
    "    if (IsDomainIP(domain)):\n",
    "        return 0\n",
    "\n",
    "    domains = domain.split('.')\n",
    "    return len(domains) - 2  # Subtract apex domain and TLD\n",
    "\n",
    "\n",
    "print(NoOfSubDomain('docs.python.org'))  # 1\n",
    "print(NoOfSubDomain('google.com'))  # 0\n",
    "print(NoOfSubDomain('192.168.1.1'))  # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/arvindbitm/PhiUSIIL/blob/main/CharConRate.ipynb\n",
    "# They are stripping 'www' and the TLD from the domain name before calculating the character continuation rate.\n",
    "# Why only 'www'? What about other subdomains?\n",
    "\n",
    "def CharConRate(url):\n",
    "    rate = 0  # This variable is not even used ðŸ¤·â€â™‚ï¸\n",
    "    ln = len(url)\n",
    "    chC, nmC, spC = 0, 0, 0\n",
    "    maxCh, maxNm, MaxSp = 0, 0, 0\n",
    "    for i in range(0, ln):\n",
    "        ch = url[i]\n",
    "        if ch.isalpha():\n",
    "            chC = chC + 1\n",
    "            if (nmC > 0):\n",
    "                if (maxNm < nmC):\n",
    "                    maxNm = nmC\n",
    "                    nmC = 0\n",
    "            elif (spC > 0):\n",
    "                if (MaxSp < spC):\n",
    "                    MaxSp = spC\n",
    "                    spC = 0\n",
    "            nmC, spC = 0, 0\n",
    "\n",
    "        elif ch.isdigit():\n",
    "            nmC = nmC + 1\n",
    "            if (chC > 0):\n",
    "                if (maxCh < chC):\n",
    "                    maxCh = chC\n",
    "                    chC = 0\n",
    "            elif (spC > 0):\n",
    "                if (MaxSp < spC):\n",
    "                    MaxSp = spC\n",
    "                    spC = 0\n",
    "            chC, spC = 0, 0\n",
    "        else:\n",
    "            spC = spC + 1\n",
    "            if (nmC > 0):\n",
    "                if (maxNm < nmC):\n",
    "                    maxNm = nmC\n",
    "                    nmC = 0\n",
    "            elif (chC > 0):\n",
    "                if (maxCh < chC):\n",
    "                    maxCh = chC\n",
    "                    chC = 0\n",
    "            nmC, chC = 0, 0\n",
    "\n",
    "    if (maxCh < chC):\n",
    "        maxCh = chC\n",
    "    if (maxNm < nmC):\n",
    "        maxNm = nmC\n",
    "    if (MaxSp < spC):\n",
    "        MaxSp = spC\n",
    "    return (maxCh + maxNm + MaxSp) / ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def HasObfuscation(str):\n",
    "    decoded_str = unquote(str)\n",
    "    return int(decoded_str != str)\n",
    "\n",
    "\n",
    "print(HasObfuscation('https://facebook.com'))\n",
    "print(HasObfuscation('https://facebook.com@%61%62%63.%43%4F%4D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "def NoOfObfuscatedChar(str):\n",
    "    # Regular expression to find percent-encoded characters.\n",
    "    # A percent-encoded character is a character that is represented by a percent sign followed by two hexadecimal digits.\n",
    "    encoded_char_pattern = r'%[0-9A-Fa-f]{2}'\n",
    "    # Find all matches of the pattern in the URL\n",
    "    encoded_chars = re.findall(encoded_char_pattern, str)\n",
    "    return len(encoded_chars)\n",
    "\n",
    "\n",
    "print(NoOfObfuscatedChar('https://facebook.com'))\n",
    "print(NoOfObfuscatedChar('https://facebook.com@%61%62%63.%43%4F%4D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def NoOfInURL(str, pattern):\n",
    "    \"\"\"\n",
    "    Counts the number of occurrences of a given pattern in a string.\n",
    "\n",
    "    Parameters:\n",
    "    - str (str): The input string to search for matches.\n",
    "    - pattern (str): The pattern to search for in the input string.\n",
    "\n",
    "    Returns:\n",
    "    - int: The number of matches found.\n",
    "\n",
    "    Example:\n",
    "    >>> NoOfInURL(\"https://facebook.com?param=value\", r\"=\")\n",
    "    1\n",
    "    \"\"\"\n",
    "    # Find all matches of the pattern in the URL\n",
    "    matches = re.findall(pattern, str)\n",
    "    return len(matches)\n",
    "\n",
    "\n",
    "print(NoOfInURL('https://facebook.com', r'\\?'))\n",
    "print(NoOfInURL('https://facebook.com?param=value', r'\\?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08333333333333333\n",
      "0.125\n"
     ]
    }
   ],
   "source": [
    "# Refering to 'URL' but seems to be calculating for 'Domain' on the dataset\n",
    "# Same applies to the all ...InURL calculations\n",
    "def SpecialCharRatioInURL(url):\n",
    "    # Negative lookahead to match any character that is not a letter or a digit\n",
    "    special_char_pattern = r'[^A-Za-z0-9]'\n",
    "    special_chars = re.findall(special_char_pattern, url)\n",
    "    return len(special_chars) / len(url)\n",
    "\n",
    "\n",
    "print(SpecialCharRatioInURL('facebook.com'))\n",
    "print(SpecialCharRatioInURL('facebook.com?param=value'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'URLLength': 43,\n",
       " 'Domain': 'www.google.com',\n",
       " 'DomainLength': 14,\n",
       " 'IsDomainIP': 0,\n",
       " 'TLD': 'com',\n",
       " 'TLDLength': 3,\n",
       " 'TLDLegitimateProb': None,\n",
       " 'URLSimilarityIndex': None,\n",
       " 'CharContinuationRate': 1.0,\n",
       " 'URLCharProb': None,\n",
       " 'NoOfSubDomain': 1,\n",
       " 'HasObfuscation': 0,\n",
       " 'NoOfObfuscatedChar': 0,\n",
       " 'ObfuscationRatio': 0.0,\n",
       " 'NoOfLettersInURL': 34,\n",
       " 'LetterRatioInURL': 0.7906976744186046,\n",
       " 'NoOfDegitsInURL': 0,\n",
       " 'DegitRatioInURL': 0.0,\n",
       " 'NoOfEqualsInURL': 1,\n",
       " 'NoOfQMarkInURL': 1,\n",
       " 'NoOfAmpersandInURL': 0,\n",
       " 'NoOfOtherSpecialCharsInURL': 7,\n",
       " 'SpacialCharRatioInURL': 0.20930232558139536,\n",
       " 'IsHTTPS': 1}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Even though most URLs in the dataset do not contains query params, those kind of URLs are more realistic.\n",
    "test_url = 'https://www.google.com/search?q=alan+turing'\n",
    "\n",
    "\n",
    "def URLFeatures(url):\n",
    "    parsed_url = urlparse(url)\n",
    "    domain = parsed_url.hostname\n",
    "    tld = domain.split('.')[-1]\n",
    "\n",
    "    return {\n",
    "        'URLLength': len(url),\n",
    "        'Domain': domain,\n",
    "        'DomainLength': len(domain),\n",
    "        'IsDomainIP': IsDomainIP(domain),\n",
    "        'TLD': tld,\n",
    "        'TLDLength': len(tld),\n",
    "        'TLDLegitimateProb': None,\n",
    "        'URLSimilarityIndex': None,\n",
    "        'CharContinuationRate': CharConRate(domain.split('.')[1 if NoOfSubDomain('google.com') > 0 else 0]),\n",
    "        # For consistency, we are stripping the first subdomain (not just 'www') and the TLD\n",
    "        'URLCharProb': None,\n",
    "        'NoOfSubDomain': NoOfSubDomain(domain),\n",
    "        'HasObfuscation': HasObfuscation(domain),\n",
    "        'NoOfObfuscatedChar': NoOfObfuscatedChar(domain),\n",
    "        'ObfuscationRatio': NoOfObfuscatedChar(domain) / len(domain),\n",
    "        'NoOfLettersInURL': NoOfInURL(url, r'[a-zA-Z]'),\n",
    "        'LetterRatioInURL': NoOfInURL(url, r'[a-zA-Z]') / len(url),\n",
    "        'NoOfDegitsInURL': NoOfInURL(url, r'\\d'),\n",
    "        'DegitRatioInURL': NoOfInURL(url, r'\\d') / len(url),\n",
    "        'NoOfEqualsInURL': NoOfInURL(url, r'='),\n",
    "        'NoOfQMarkInURL': NoOfInURL(url, r'\\?'),\n",
    "        'NoOfAmpersandInURL': NoOfInURL(url, r'&'),\n",
    "        'NoOfOtherSpecialCharsInURL': NoOfInURL(url, r'[^a-zA-Z\\d=&\\?]'),\n",
    "        'SpacialCharRatioInURL': SpecialCharRatioInURL(url),\n",
    "        # I guess this is a typo and it should be 'SpecialCharRatioInURL'\n",
    "        'IsHTTPS': int(parsed_url.scheme == 'https'),\n",
    "    }\n",
    "\n",
    "\n",
    "URLFeatures(test_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract HTML features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following features are extracted from the web page HTML:\n",
    "\n",
    "- **LineOfCode**: Number of lines of code in the HTML.\n",
    "- **LargestLineLength**: Length of the largest line of code in the HTML. This is used to detect obfuscated code.\n",
    "- **HasTitle**: Whether the HTML has a title tag.\n",
    "- **Title**: The title of the page.\n",
    "- **DomainTitleMatchScore**: The score of the page title matching the domain name. Out of 100.\n",
    "- **URLTitleMatchScore**: The score of the page title matching the URL. Out of 100.\n",
    "- **HasFavicon**: Whether the page has a favicon.\n",
    "- **Robots**: Does the website have a robots.txt file or a robots meta tag.\n",
    "- **IsResponsive**: Whether the website is responsive.\n",
    "- **NoOfURLRedirect**: Number of URL redirects.\n",
    "- **NoOfSelfRedirect**: Number of redirects to the same domain.\n",
    "- **HasDescription**: Whether the page has a meta description.\n",
    "- **NoOfPopup**: Number of popups.\n",
    "- **NoOfiFrame**: Number of iframes.\n",
    "- **HasExternalFormSubmit**: Whether the page has an external form submit.\n",
    "- **HasSocialNet**: Whether the page has social network links.\n",
    "- **HasSubmitButton**: Whether the page has a submit button.\n",
    "- **HasHiddenFields**: Whether the page has hidden fields.\n",
    "- **HasPasswordField**: Whether the page has password fields.\n",
    "- **Bank**: Whether the page is a bank page.\n",
    "- **Pay**: Whether the page is a payment page.\n",
    "- **Crypto**: Whether the page is a cryptocurrency page.\n",
    "- **HasCopyrightInfo**: Whether the page has copyright information.\n",
    "- **NoOfImage**: Number of images.\n",
    "- **NoOfCSS**: Number of CSS files.\n",
    "- **NoOfJS**: Number of JS files.\n",
    "- **NoOfSelfRef**: Number of links to the same domain.\n",
    "- **NoOfEmptyRef**: Number of empty links.\n",
    "- **NoOfExternalRef**: Number of links to external domains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LineOfCode(html):\n",
    "    return len(re.findall('\\n', html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LargestLineLength(html):\n",
    "    max = 0\n",
    "    for line in html.split('\\n'):\n",
    "        if len(line) > max:\n",
    "            max = len(line)\n",
    "    return max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HasFavicon(url: str, soup: BeautifulSoup):\n",
    "    favicon = soup.find('link', rel='icon')\n",
    "    if favicon is not None:\n",
    "        return int(True)\n",
    "\n",
    "    favicon_url = urlparse(url)._replace(path='/favicon.ico').geturl()\n",
    "    response = requests.get(favicon_url)\n",
    "    if response.status_code == 200:\n",
    "        return int(True)\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HasRobots(url: str, soup: BeautifulSoup):\n",
    "    # Check if meta robots tag exists before making a request\n",
    "    if soup:\n",
    "        meta = soup.find('meta', attrs={'name': 'robots'})\n",
    "        if meta:\n",
    "            return int(True)  # for readability\n",
    "\n",
    "    # If no meta tag, make a request to the robots.txt file\n",
    "    if url:\n",
    "        robots_url = urlparse(url)._replace(path='/robots.txt').geturl()\n",
    "        response = requests.get(robots_url)\n",
    "        if response.status_code == 200:\n",
    "            return int(True)\n",
    "\n",
    "    return int(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IsResponsive(soup: BeautifulSoup):\n",
    "    # Check if viewport meta tag exists\n",
    "    meta = soup.find('meta', attrs={'name': 'viewport'})\n",
    "    if meta:\n",
    "        return int(True)\n",
    "\n",
    "    # Check for conditionally loaded stylesheets\n",
    "    stylesheet = soup.find('link', attrs={'rel': 'stylesheet', 'media': 'screen'})\n",
    "    if stylesheet:\n",
    "        return int(True)\n",
    "\n",
    "    # Check if inline style contains media queries\n",
    "    style = soup.find('style', string=re.compile('@media'))\n",
    "    if style:\n",
    "        return int(True)\n",
    "\n",
    "    # Checking if the page is responsive is not a trivial task\n",
    "    # This function may return false negatives\n",
    "    # For example, a page may be responsive without using media queries.\n",
    "    # Above checks don't cover all possible cases.\n",
    "\n",
    "    return int(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NoOfPopup(soup: BeautifulSoup):\n",
    "    count = 0\n",
    "\n",
    "    # Check for new dialog element\n",
    "    popups = soup.find_all('dialog')\n",
    "    count += len(popups)\n",
    "\n",
    "    # Check for window.open() calls\n",
    "    scripts = soup.find_all('script', string=re.compile('window.open'))\n",
    "    count += len(scripts)\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HasExternalFormSubmit(soup: BeautifulSoup):\n",
    "    forms = soup.find_all('form')\n",
    "    for form in forms:\n",
    "        action = form.get('action')\n",
    "        if action and not action.startswith('/'):\n",
    "            return int(True)\n",
    "\n",
    "    return int(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HasSocialNet(soup: BeautifulSoup):\n",
    "    social_media = [\n",
    "        'facebook', 'twitter', 'x.com', 'linkedin', 'instagram', 'youtube',\n",
    "        'pinterest', 'tumblr', 'snapchat', 'reddit', 'tiktok', 'whatsapp',\n",
    "        'wechat', 'qq', 'telegram', 'viber', 'line', 'vk', 'odnoklassniki',\n",
    "        'myspace', 'flickr', 'meetup', 'mix', 'deviantart', 'livejournal',\n",
    "        'badoo', 'stumbleupon', 'digg', 'friendster', 'classmates', 'xing',\n",
    "        'renren', 'douban', 'vkontakte', 'qzone', 'baidu', 'weibo', 'kakao',\n",
    "        'naver', 'skype', 'discord', 'slack', 'signal', 'mastodon', 'parler',\n",
    "        'gab', 'clubhouse', 'ello', 'peach', 'plurk', 'mewe', 'minds', 'diaspora'\n",
    "    ]\n",
    "\n",
    "    social_media_regex = re.compile('|'.join(social_media), re.IGNORECASE)\n",
    "\n",
    "    # Check if any social media link exists (no need to check all)\n",
    "    social_media_link = soup.find('a', href=social_media_regex)\n",
    "\n",
    "    if social_media_link:\n",
    "        return int(True)\n",
    "\n",
    "    return int(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HasCopyrightInfo(soup: BeautifulSoup):\n",
    "    copyright_variants = ['Â©', '(c)', 'copyright', 'all rights reserved']\n",
    "    copyright_regex = re.compile('|'.join(copyright_variants), re.IGNORECASE)\n",
    "\n",
    "    return int(soup.find(string=copyright_regex) is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count self-referencing links\n",
    "def NoOfSelfRef(soup: BeautifulSoup):\n",
    "    count = 0\n",
    "\n",
    "    links = soup.find_all('a')\n",
    "    for link in links:\n",
    "        href = link.get('href')\n",
    "        if href is not None and (href.startswith('/') or href.startswith('#')):\n",
    "            count += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "\n",
    "# Count empty links\n",
    "def NoOfEmptyRef(soup: BeautifulSoup):\n",
    "    count = 0\n",
    "\n",
    "    links = soup.find_all('a')\n",
    "    for link in links:\n",
    "        href = link.get('href')\n",
    "        if href is None or href == '':\n",
    "            count += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "\n",
    "# Count external links\n",
    "def NoOfExternalRef(url: str, soup: BeautifulSoup):\n",
    "    count = 0\n",
    "    netloc = urlparse(url).netloc\n",
    "\n",
    "    links = soup.find_all('a')\n",
    "    for link in links:\n",
    "        href = link.get('href')\n",
    "        if href is not None and urlparse(href).netloc != netloc:\n",
    "            count += 1\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LineOfCode': 30,\n",
       " 'LargestLineLength': 45695,\n",
       " 'HasTitle': 1,\n",
       " 'Title': 'alan turing - Recherche Google',\n",
       " 'DomainTitleMatchScore': None,\n",
       " 'URLTitleMatchScore': None,\n",
       " 'HasFavicon': 1,\n",
       " 'Robots': 1,\n",
       " 'IsResponsive': 0,\n",
       " 'NoOfURLRedirect': 0,\n",
       " 'NoOfSelfRedirect': 0,\n",
       " 'HasDescription': 0,\n",
       " 'NoOfPopup': 0,\n",
       " 'NoOfiFrame': 0,\n",
       " 'HasExternalFormSubmit': 0,\n",
       " 'HasSocialNet': 1,\n",
       " 'HasSubmitButton': 0,\n",
       " 'HasHiddenFields': 1,\n",
       " 'HasPasswordField': 0,\n",
       " 'Bank': None,\n",
       " 'Pay': None,\n",
       " 'Crypto': None,\n",
       " 'HasCopyrightInfo': 1,\n",
       " 'NoOfImage': 9,\n",
       " 'NoOfCSS': 0,\n",
       " 'NoOfJS': 9,\n",
       " 'NoOfSelfRef': 54,\n",
       " 'NoOfEmptyRef': 0,\n",
       " 'NoOfExternalRef': 56}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_url = 'https://www.google.com/search?q=alan+turing'  # Link with robots.txt\n",
    "\n",
    "\n",
    "# test_url = 'https://shorturl.at/qzDIE' # Link with redirects\n",
    "# test_url = 'https://example.com'\n",
    "\n",
    "def HTMLFeatures(url):\n",
    "    response = requests.get(url, allow_redirects=True)\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    return {\n",
    "        'LineOfCode': LineOfCode(html),\n",
    "        'LargestLineLength': LargestLineLength(html),\n",
    "        'HasTitle': int(soup.title is not None),\n",
    "        'Title': soup.title.string if soup.title else '',\n",
    "        'DomainTitleMatchScore': None,\n",
    "        'URLTitleMatchScore': None,\n",
    "        'HasFavicon': HasFavicon(url, soup),\n",
    "        'Robots': HasRobots(url, soup),\n",
    "        'IsResponsive': IsResponsive(soup),\n",
    "        'NoOfURLRedirect': len(response.history),\n",
    "        'NoOfSelfRedirect': len([redirect for redirect in response.history[1:] if\n",
    "                                 urlparse(redirect.url).hostname == urlparse(url).hostname]),\n",
    "        'HasDescription': int(soup.find('meta', attrs={'name': 'description'}) is not None),\n",
    "        'NoOfPopup': NoOfPopup(soup),\n",
    "        'NoOfiFrame': len(soup.find_all('iframe')),\n",
    "        'HasExternalFormSubmit': HasExternalFormSubmit(soup),\n",
    "        'HasSocialNet': HasSocialNet(soup),\n",
    "        'HasSubmitButton': int(soup.find('input', type='submit') is not None),\n",
    "        'HasHiddenFields': int(soup.find('input', type='hidden') is not None),\n",
    "        'HasPasswordField': int(soup.find('input', type='password') is not None),\n",
    "        'Bank': None,\n",
    "        'Pay': None,\n",
    "        'Crypto': None,\n",
    "        'HasCopyrightInfo': HasCopyrightInfo(soup),\n",
    "        'NoOfImage': len(soup.find_all('img')),\n",
    "        'NoOfCSS': len(soup.find_all('link', rel='stylesheet')),\n",
    "        'NoOfJS': len(soup.find_all('script')),\n",
    "        'NoOfSelfRef': NoOfSelfRef(soup),\n",
    "        'NoOfEmptyRef': NoOfEmptyRef(soup),\n",
    "        'NoOfExternalRef': NoOfExternalRef(url, soup),\n",
    "    }\n",
    "\n",
    "\n",
    "HTMLFeatures(test_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
