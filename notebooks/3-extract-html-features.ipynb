{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn raw data into features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract HTML features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following features are extracted from the web page HTML:\n",
    "\n",
    "- **LineOfCode**: Number of lines of code in the HTML.\n",
    "- **LargestLineLength**: Length of the largest line of code in the HTML. This is used to detect obfuscated code.\n",
    "- **HasTitle**: Whether the HTML has a title tag.\n",
    "- **Title**: The title of the page.\n",
    "- **DomainTitleMatchScore**: The score of the page title matching the domain name. Out of 100.\n",
    "- **URLTitleMatchScore**: The score of the page title matching the URL. Out of 100.\n",
    "- **HasFavicon**: Whether the page has a favicon.\n",
    "- **Robots**: Does the website have a robots.txt file or a robots meta tag.\n",
    "- **IsResponsive**: Whether the website is responsive.\n",
    "- **NoOfURLRedirect**: Number of URL redirects.\n",
    "- **NoOfSelfRedirect**: Number of redirects to the same domain.\n",
    "- **HasDescription**: Whether the page has a meta description.\n",
    "- **NoOfPopup**: Number of popups.\n",
    "- **NoOfiFrame**: Number of iframes.\n",
    "- **HasExternalFormSubmit**: Whether the page has an external form submit.\n",
    "- **HasSocialNet**: Whether the page has social network links.\n",
    "- **HasSubmitButton**: Whether the page has a submit button.\n",
    "- **HasHiddenFields**: Whether the page has hidden fields.\n",
    "- **HasPasswordField**: Whether the page has password fields.\n",
    "- **Bank**: Whether the page is a bank page.\n",
    "- **Pay**: Whether the page is a payment page.\n",
    "- **Crypto**: Whether the page is a cryptocurrency page.\n",
    "- **HasCopyrightInfo**: Whether the page has copyright information.\n",
    "- **NoOfImage**: Number of images.\n",
    "- **NoOfCSS**: Number of CSS files.\n",
    "- **NoOfJS**: Number of JS files.\n",
    "- **NoOfSelfRef**: Number of links to the same domain.\n",
    "- **NoOfEmptyRef**: Number of empty links.\n",
    "- **NoOfExternalRef**: Number of links to external domains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /Users/alex/anaconda3/envs/phishing-url/lib/python3.12/site-packages (4.12.3)\n",
      "Requirement already satisfied: requests in /Users/alex/anaconda3/envs/phishing-url/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/alex/anaconda3/envs/phishing-url/lib/python3.12/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/alex/anaconda3/envs/phishing-url/lib/python3.12/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/alex/anaconda3/envs/phishing-url/lib/python3.12/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/alex/anaconda3/envs/phishing-url/lib/python3.12/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alex/anaconda3/envs/phishing-url/lib/python3.12/site-packages (from requests) (2024.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install beautifulsoup4 requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LineOfCode(html):\n",
    "    return len(re.findall('\\n', html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LargestLineLength(html):\n",
    "    max = 0\n",
    "    for line in html.split('\\n'):\n",
    "        if len(line) > max:\n",
    "            max = len(line)\n",
    "    return max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HasFavicon(url: str, soup: BeautifulSoup):\n",
    "    favicon = soup.find('link', rel='icon')\n",
    "    if favicon is not None:\n",
    "        return int(True)\n",
    "\n",
    "    favicon_url = urlparse(url)._replace(path='/favicon.ico').geturl()\n",
    "    response = requests.get(favicon_url)\n",
    "    if response.status_code == 200:\n",
    "        return int(True)\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HasRobots(url: str, soup: BeautifulSoup):\n",
    "    # Check if meta robots tag exists before making a request\n",
    "    if soup:\n",
    "        meta = soup.find('meta', attrs={'name': 'robots'})\n",
    "        if meta:\n",
    "            return int(True) # for readability\n",
    "    \n",
    "    # If no meta tag, make a request to the robots.txt file\n",
    "    if url:\n",
    "        robots_url = urlparse(url)._replace(path='/robots.txt').geturl()\n",
    "        response = requests.get(robots_url)\n",
    "        if response.status_code == 200:\n",
    "            return int(True)\n",
    "    \n",
    "    return int(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IsResponsive(soup: BeautifulSoup):\n",
    "    # Check if viewport meta tag exists\n",
    "    meta = soup.find('meta', attrs={'name': 'viewport'})\n",
    "    if meta:\n",
    "        return int(True)\n",
    "\n",
    "    # Check for conditionally loaded stylesheets\n",
    "    stylesheet = soup.find('link', attrs={'rel': 'stylesheet', 'media': 'screen'})\n",
    "    if stylesheet:\n",
    "        return int(True)\n",
    "\n",
    "    # Check if inline style contains media queries\n",
    "    style = soup.find('style', string=re.compile('@media'))\n",
    "    if style:\n",
    "        return int(True)\n",
    "    \n",
    "    # Checking if the page is responsive is not a trivial task\n",
    "    # This function may return false negatives\n",
    "    # For example, a page may be responsive without using media queries.\n",
    "    # Above checks don't cover all possible cases.\n",
    "    \n",
    "    return int(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NoOfPopup(soup: BeautifulSoup):\n",
    "    count = 0\n",
    "    \n",
    "    # Check for new dialog element\n",
    "    popups = soup.find_all('dialog')\n",
    "    count += len(popups)\n",
    "\n",
    "    # Check for window.open() calls\n",
    "    scripts = soup.find_all('script', string=re.compile('window.open'))\n",
    "    count += len(scripts)\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HasExternalFormSubmit(soup: BeautifulSoup):\n",
    "    forms = soup.find_all('form')\n",
    "    for form in forms:\n",
    "        action = form.get('action')\n",
    "        if action and not action.startswith('/'):\n",
    "            return int(True)\n",
    "    \n",
    "    return int(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HasSocialNet(soup: BeautifulSoup):\n",
    "    social_media = [\n",
    "        'facebook', 'twitter', 'x.com', 'linkedin', 'instagram', 'youtube', \n",
    "        'pinterest', 'tumblr', 'snapchat', 'reddit', 'tiktok', 'whatsapp', \n",
    "        'wechat', 'qq', 'telegram', 'viber', 'line', 'vk', 'odnoklassniki', \n",
    "        'myspace', 'flickr', 'meetup', 'mix', 'deviantart', 'livejournal', \n",
    "        'badoo', 'stumbleupon', 'digg', 'friendster', 'classmates', 'xing', \n",
    "        'renren', 'douban', 'vkontakte', 'qzone', 'baidu', 'weibo', 'kakao', \n",
    "        'naver', 'skype', 'discord', 'slack', 'signal', 'mastodon', 'parler', \n",
    "        'gab', 'clubhouse', 'ello', 'peach', 'plurk', 'mewe', 'minds', 'diaspora'\n",
    "    ]\n",
    "\n",
    "    social_media_regex = re.compile('|'.join(social_media), re.IGNORECASE)\n",
    "    \n",
    "    # Check if any social media link exists (no need to check all)\n",
    "    social_media_link = soup.find('a', href=social_media_regex)\n",
    "\n",
    "    if social_media_link:\n",
    "        return int(True)\n",
    "    \n",
    "    return int(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HasCopyrightInfo(soup: BeautifulSoup):\n",
    "    copyright_variants = ['Â©', '(c)', 'copyright', 'all rights reserved']\n",
    "    copyright_regex = re.compile('|'.join(copyright_variants), re.IGNORECASE)\n",
    "    \n",
    "    return int(soup.find(string=copyright_regex) is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count self-referencing links\n",
    "def NoOfSelfRef(soup: BeautifulSoup):\n",
    "    count = 0\n",
    "    \n",
    "    links = soup.find_all('a')\n",
    "    for link in links:\n",
    "        href = link.get('href')\n",
    "        if href is not None and (href.startswith('/') or href.startswith('#')):\n",
    "            count += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "# Count empty links\n",
    "def NoOfEmptyRef(soup: BeautifulSoup):\n",
    "    count = 0\n",
    "    \n",
    "    links = soup.find_all('a')\n",
    "    for link in links:\n",
    "        href = link.get('href')\n",
    "        if href is None or href == '':\n",
    "            count += 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "# Count external links\n",
    "def NoOfExternalRef(url: str, soup: BeautifulSoup):\n",
    "    count = 0\n",
    "    netloc = urlparse(url).netloc\n",
    "    \n",
    "    links = soup.find_all('a')\n",
    "    for link in links:\n",
    "        href = link.get('href')\n",
    "        if href is not None and urlparse(href).netloc != netloc:\n",
    "            count += 1\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LineOfCode': 30,\n",
       " 'LargestLineLength': 45695,\n",
       " 'HasTitle': 1,\n",
       " 'Title': 'alan turing - Recherche Google',\n",
       " 'DomainTitleMatchScore': None,\n",
       " 'URLTitleMatchScore': None,\n",
       " 'HasFavicon': 1,\n",
       " 'Robots': 1,\n",
       " 'IsResponsive': 0,\n",
       " 'NoOfURLRedirect': 0,\n",
       " 'NoOfSelfRedirect': 0,\n",
       " 'HasDescription': 0,\n",
       " 'NoOfPopup': 0,\n",
       " 'NoOfiFrame': 0,\n",
       " 'HasExternalFormSubmit': 0,\n",
       " 'HasSocialNet': 1,\n",
       " 'HasSubmitButton': 0,\n",
       " 'HasHiddenFields': 1,\n",
       " 'HasPasswordField': 0,\n",
       " 'Bank': None,\n",
       " 'Pay': None,\n",
       " 'Crypto': None,\n",
       " 'HasCopyrightInfo': 1,\n",
       " 'NoOfImage': 9,\n",
       " 'NoOfCSS': 0,\n",
       " 'NoOfJS': 9,\n",
       " 'NoOfSelfRef': 54,\n",
       " 'NoOfEmptyRef': 0,\n",
       " 'NoOfExternalRef': 56}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_url = 'https://www.google.com/search?q=alan+turing' # Link with robots.txt\n",
    "# test_url = 'https://shorturl.at/qzDIE' # Link with redirects\n",
    "# test_url = 'https://example.com'\n",
    "\n",
    "def HTMLFeatures(url):\n",
    "    response = requests.get(url, allow_redirects=True)\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    return {\n",
    "        'LineOfCode': LineOfCode(html),\n",
    "        'LargestLineLength': LargestLineLength(html),\n",
    "        'HasTitle': int(soup.title is not None),\n",
    "        'Title': soup.title.string if soup.title else '',\n",
    "        'DomainTitleMatchScore': None,\n",
    "        'URLTitleMatchScore': None,\n",
    "        'HasFavicon': HasFavicon(url, soup),\n",
    "        'Robots': HasRobots(url, soup),\n",
    "        'IsResponsive': IsResponsive(soup),\n",
    "        'NoOfURLRedirect': len(response.history),\n",
    "        'NoOfSelfRedirect': len([redirect for redirect in response.history[1:] if urlparse(redirect.url).hostname == urlparse(url).hostname]),\n",
    "        'HasDescription': int(soup.find('meta', attrs={'name': 'description'}) is not None),\n",
    "        'NoOfPopup': NoOfPopup(soup),\n",
    "        'NoOfiFrame': len(soup.find_all('iframe')),\n",
    "        'HasExternalFormSubmit': HasExternalFormSubmit(soup),\n",
    "        'HasSocialNet': HasSocialNet(soup),\n",
    "        'HasSubmitButton': int(soup.find('input', type='submit') is not None),\n",
    "        'HasHiddenFields': int(soup.find('input', type='hidden') is not None),\n",
    "        'HasPasswordField': int(soup.find('input', type='password') is not None),\n",
    "        'Bank': None,\n",
    "        'Pay': None,\n",
    "        'Crypto': None,\n",
    "        'HasCopyrightInfo': HasCopyrightInfo(soup),\n",
    "        'NoOfImage': len(soup.find_all('img')),\n",
    "        'NoOfCSS': len(soup.find_all('link', rel='stylesheet')),\n",
    "        'NoOfJS': len(soup.find_all('script')),\n",
    "        'NoOfSelfRef': NoOfSelfRef(soup),\n",
    "        'NoOfEmptyRef': NoOfEmptyRef(soup),\n",
    "        'NoOfExternalRef': NoOfExternalRef(url, soup),\n",
    "    }\n",
    "\n",
    "HTMLFeatures(test_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
